{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- Step 1: Load Data and Initial Inspection ---\n",
        "print(\"--- Step 1: Load Data and Initial Inspection ---\")\n",
        "file_path = 'WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
        "df = None # Initialize df to None\n",
        "\n",
        "try:\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Dataset '{file_path}' loaded successfully.\")\n",
        "\n",
        "    # Display the first 5 rows\n",
        "    print(\"\\nFirst 5 rows of the raw dataset:\")\n",
        "    print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "    # Display basic info\n",
        "    print(\"\\nInitial Dataset Info:\")\n",
        "    df.info()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    # Exit or handle error appropriately if file not found\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during loading: {e}\")\n",
        "    # Exit or handle error appropriately\n",
        "    exit()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Load Data and Initial Inspection ---\n",
            "Dataset 'WA_Fn-UseC_-HR-Employee-Attrition.csv' loaded successfully.\n",
            "\n",
            "First 5 rows of the raw dataset:\n",
            "| Age   | Attrition   | BusinessTravel    | DailyRate   | Department             | DistanceFromHome   | Education   | EducationField   | EmployeeCount   | EmployeeNumber   | EnvironmentSatisfaction   | Gender   | HourlyRate   | JobInvolvement   | JobLevel   | JobRole               | JobSatisfaction   | MaritalStatus   | MonthlyIncome   | MonthlyRate   | NumCompaniesWorked   | Over18   | OverTime   | PercentSalaryHike   | PerformanceRating   | RelationshipSatisfaction   | StandardHours   | StockOptionLevel   | TotalWorkingYears   | TrainingTimesLastYear   | WorkLifeBalance   | YearsAtCompany   | YearsInCurrentRole   | YearsSinceLastPromotion   | YearsWithCurrManager   |\n",
            "|:------|:------------|:------------------|:------------|:-----------------------|:-------------------|:------------|:-----------------|:----------------|:-----------------|:--------------------------|:---------|:-------------|:-----------------|:-----------|:----------------------|:------------------|:----------------|:----------------|:--------------|:---------------------|:---------|:-----------|:--------------------|:--------------------|:---------------------------|:----------------|:-------------------|:--------------------|:------------------------|:------------------|:-----------------|:---------------------|:--------------------------|:-----------------------|\n",
            "| 41    | Yes         | Travel_Rarely     | 1102        | Sales                  | 1                  | 2           | Life Sciences    | 1               | 1                | 2                         | Female   | 94           | 3                | 2          | Sales Executive       | 4                 | Single          | 5993            | 19479         | 8                    | Y        | Yes        | 11                  | 3                   | 1                          | 80              | 0                  | 8                   | 0                       | 1                 | 6                | 4                    | 0                         | 5                      |\n",
            "| 49    | No          | Travel_Frequently | 279         | Research & Development | 8                  | 1           | Life Sciences    | 1               | 2                | 3                         | Male     | 61           | 2                | 2          | Research Scientist    | 2                 | Married         | 5130            | 24907         | 1                    | Y        | No         | 23                  | 4                   | 4                          | 80              | 1                  | 10                  | 3                       | 3                 | 10               | 7                    | 1                         | 7                      |\n",
            "| 37    | Yes         | Travel_Rarely     | 1373        | Research & Development | 2                  | 2           | Other            | 1               | 4                | 4                         | Male     | 92           | 2                | 1          | Laboratory Technician | 3                 | Single          | 2090            | 2396          | 6                    | Y        | Yes        | 15                  | 3                   | 2                          | 80              | 0                  | 7                   | 3                       | 3                 | 0                | 0                    | 0                         | 0                      |\n",
            "| 33    | No          | Travel_Frequently | 1392        | Research & Development | 3                  | 4           | Life Sciences    | 1               | 5                | 4                         | Female   | 56           | 3                | 1          | Research Scientist    | 3                 | Married         | 2909            | 23159         | 1                    | Y        | Yes        | 11                  | 3                   | 3                          | 80              | 0                  | 8                   | 3                       | 3                 | 8                | 7                    | 3                         | 0                      |\n",
            "| 27    | No          | Travel_Rarely     | 591         | Research & Development | 2                  | 1           | Medical          | 1               | 7                | 1                         | Male     | 40           | 3                | 1          | Laboratory Technician | 2                 | Married         | 3468            | 16632         | 9                    | Y        | No         | 12                  | 3                   | 4                          | 80              | 1                  | 6                   | 3                       | 3                 | 2                | 2                    | 2                         | 2                      |\n",
            "\n",
            "Initial Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 35 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Age                       1470 non-null   int64 \n",
            " 1   Attrition                 1470 non-null   object\n",
            " 2   BusinessTravel            1470 non-null   object\n",
            " 3   DailyRate                 1470 non-null   int64 \n",
            " 4   Department                1470 non-null   object\n",
            " 5   DistanceFromHome          1470 non-null   int64 \n",
            " 6   Education                 1470 non-null   int64 \n",
            " 7   EducationField            1470 non-null   object\n",
            " 8   EmployeeCount             1470 non-null   int64 \n",
            " 9   EmployeeNumber            1470 non-null   int64 \n",
            " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
            " 11  Gender                    1470 non-null   object\n",
            " 12  HourlyRate                1470 non-null   int64 \n",
            " 13  JobInvolvement            1470 non-null   int64 \n",
            " 14  JobLevel                  1470 non-null   int64 \n",
            " 15  JobRole                   1470 non-null   object\n",
            " 16  JobSatisfaction           1470 non-null   int64 \n",
            " 17  MaritalStatus             1470 non-null   object\n",
            " 18  MonthlyIncome             1470 non-null   int64 \n",
            " 19  MonthlyRate               1470 non-null   int64 \n",
            " 20  NumCompaniesWorked        1470 non-null   int64 \n",
            " 21  Over18                    1470 non-null   object\n",
            " 22  OverTime                  1470 non-null   object\n",
            " 23  PercentSalaryHike         1470 non-null   int64 \n",
            " 24  PerformanceRating         1470 non-null   int64 \n",
            " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
            " 26  StandardHours             1470 non-null   int64 \n",
            " 27  StockOptionLevel          1470 non-null   int64 \n",
            " 28  TotalWorkingYears         1470 non-null   int64 \n",
            " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
            " 30  WorkLifeBalance           1470 non-null   int64 \n",
            " 31  YearsAtCompany            1470 non-null   int64 \n",
            " 32  YearsInCurrentRole        1470 non-null   int64 \n",
            " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
            " 34  YearsWithCurrManager      1470 non-null   int64 \n",
            "dtypes: int64(26), object(9)\n",
            "memory usage: 402.1+ KB\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NNhzLEiso45",
        "outputId": "227f1465-80c2-49d2-d455-4ceec0e26f82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Check for Missing Values ---\n",
        "print(\"\\n--- Step 2: Check for Missing Values ---\")\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0]\n",
        "\n",
        "if missing_values.empty:\n",
        "    print(\"No missing values found.\")\n",
        "else:\n",
        "    print(\"\\nColumns with missing values and counts:\")\n",
        "    print(missing_values.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "    # Add handling logic here if missing values were found (e.g., imputation, dropping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cunqqsn3tiGz",
        "outputId": "51a50dc5-62f4-4851-8338-ec470d9b1bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 2: Check for Missing Values ---\n",
            "No missing values found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Check for Duplicate Rows ---\n",
        "print(\"\\n--- Step 3: Check for Duplicate Rows ---\")\n",
        "num_duplicates = df.duplicated().sum()\n",
        "\n",
        "if num_duplicates == 0:\n",
        "    print(\"No duplicate rows found.\")\n",
        "else:\n",
        "    print(f\"Found {num_duplicates} duplicate rows.\")\n",
        "    # Remove duplicates\n",
        "    print(\"Removing duplicate rows...\")\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print(f\"Duplicates removed. New shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuEyashotYtl",
        "outputId": "9a5b74c0-aacd-43d1-f63c-fa81f7ca0fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 3: Check for Duplicate Rows ---\n",
            "No duplicate rows found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Identify and Remove Columns with Only One Value ---\n",
        "print(\"\\n--- Step 4: Identify and Remove Single-Value Columns ---\")\n",
        "unique_counts = df.nunique()\n",
        "single_value_cols = unique_counts[unique_counts == 1].index.tolist()\n",
        "\n",
        "if not single_value_cols:\n",
        "    print(\"No columns with only a single unique value found.\")\n",
        "else:\n",
        "    print(f\"\\nColumns with only one value: {', '.join(single_value_cols)}\")\n",
        "    print(f\"Dropping single-value columns...\")\n",
        "    df.drop(columns=single_value_cols, inplace=True)\n",
        "    print(f\"Columns dropped. New shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FhIjH2otoN7",
        "outputId": "010d963b-cbab-4011-df02-944f0ff2d6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Identify and Remove Single-Value Columns ---\n",
            "\n",
            "Columns with only one value: EmployeeCount, Over18, StandardHours\n",
            "Dropping single-value columns...\n",
            "Columns dropped. New shape: (1470, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Identify Potential Outliers (Example: MonthlyIncome) ---\n",
        "print(\"\\n--- Step 5: Identify Potential Outliers (Example: MonthlyIncome) ---\")\n",
        "numerical_column_to_check = 'MonthlyIncome'\n",
        "\n",
        "if numerical_column_to_check in df.columns and pd.api.types.is_numeric_dtype(df[numerical_column_to_check]):\n",
        "    Q1 = df[numerical_column_to_check].quantile(0.25)\n",
        "    Q3 = df[numerical_column_to_check].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers_mask = (df[numerical_column_to_check] < lower_bound) | (df[numerical_column_to_check] > upper_bound)\n",
        "    num_outliers = outliers_mask.sum()\n",
        "\n",
        "    if num_outliers == 0:\n",
        "        print(f\"No potential outliers found in '{numerical_column_to_check}' based on IQR.\")\n",
        "    else:\n",
        "        print(f\"Potential outliers identified in '{numerical_column_to_check}': {num_outliers}\")\n",
        "        print(f\"  - Lower Bound: {lower_bound:.2f}, Upper Bound: {upper_bound:.2f}\")\n",
        "        print(\"  (Note: Outlier handling requires domain knowledge/specific analysis goals)\")\n",
        "else:\n",
        "    print(f\"Column '{numerical_column_to_check}' not found or is not numeric.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxHfB4mftq8d",
        "outputId": "9da483bf-5958-465a-a519-3c19b6761f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 5: Identify Potential Outliers (Example: MonthlyIncome) ---\n",
            "Potential outliers identified in 'MonthlyIncome': 114\n",
            "  - Lower Bound: -5291.00, Upper Bound: 16581.00\n",
            "  (Note: Outlier handling requires domain knowledge/specific analysis goals)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Encode Categorical Variables ---\n",
        "print(\"\\n--- Step 6: Encode Categorical Variables ---\")\n",
        "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "# EmployeeNumber is an identifier, not typically encoded\n",
        "# Attrition is often the target, mapped separately if needed\n",
        "cols_to_encode = [col for col in categorical_cols if col not in ['Attrition', 'EmployeeNumber']]\n",
        "\n",
        "if not cols_to_encode:\n",
        "    print(\"No categorical columns identified for encoding (excluding Attrition).\")\n",
        "else:\n",
        "    print(f\"Encoding columns: {', '.join(cols_to_encode)}\")\n",
        "    # Using one-hot encoding\n",
        "    df = pd.get_dummies(df, columns=cols_to_encode, drop_first=True, dtype=int)\n",
        "    print(\"Categorical columns encoded.\")\n",
        "    print(f\"DataFrame shape after encoding: {df.shape}\")\n",
        "\n",
        "# Map 'Attrition' if it's still an object type\n",
        "if 'Attrition' in df.columns and df['Attrition'].dtype == 'object':\n",
        "    print(\"Mapping 'Attrition' column (Yes=1, No=0)...\")\n",
        "    df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "    print(\"'Attrition' mapped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLy4ggWDtwfj",
        "outputId": "91f2f622-2fe2-49c5-b6a1-c5678c8de1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 6: Encode Categorical Variables ---\n",
            "Encoding columns: BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime\n",
            "Categorical columns encoded.\n",
            "DataFrame shape after encoding: (1470, 46)\n",
            "Mapping 'Attrition' column (Yes=1, No=0)...\n",
            "'Attrition' mapped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7: Normalize/Scale Numerical Features (Example - Optional) ---\n",
        "print(\"\\n--- Step 7: Normalize/Scale Numerical Features (Example) ---\")\n",
        "# Scaling is often data/model dependent. This demonstrates Min-Max scaling.\n",
        "# Decide if you need this for your specific visualization/analysis.\n",
        "\n",
        "# Identify numerical columns suitable for scaling\n",
        "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "# Define columns to exclude (identifiers, target, ordinal, one-hot encoded)\n",
        "cols_to_exclude_from_scaling = ['Attrition', 'EmployeeNumber',\n",
        "                                'Education', 'EnvironmentSatisfaction', 'JobInvolvement',\n",
        "                                'JobLevel', 'JobSatisfaction', 'PerformanceRating',\n",
        "                                'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance']\n",
        "one_hot_cols = [col for col in df.columns if '_' in col or col in ['Gender_Male', 'OverTime_Yes']] # Adjust if needed\n",
        "cols_to_exclude_from_scaling.extend(one_hot_cols)\n",
        "cols_to_scale = [col for col in numerical_cols if col not in cols_to_exclude_from_scaling]\n",
        "\n",
        "if not cols_to_scale:\n",
        "    print(\"No numerical columns identified for scaling based on exclusion criteria.\")\n",
        "else:\n",
        "    print(f\"Columns identified for potential scaling: {', '.join(cols_to_scale)}\")\n",
        "    scaler = MinMaxScaler()\n",
        "    # Example: Create a scaled copy (don't modify df unless intended)\n",
        "    df_scaled_example = df.copy()\n",
        "    df_scaled_example[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
        "    print(\"Example scaling applied (to df_scaled_example, not df). First 5 Age/MonthlyIncome:\")\n",
        "    print(df_scaled_example[['Age', 'MonthlyIncome']].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "    # To apply scaling permanently: df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G6EwHk7tzcj",
        "outputId": "7adaf23b-d65d-4611-caa0-eab6e3e14073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 7: Normalize/Scale Numerical Features (Example) ---\n",
            "Columns identified for potential scaling: Age, DailyRate, DistanceFromHome, HourlyRate, MonthlyIncome, MonthlyRate, NumCompaniesWorked, PercentSalaryHike, TotalWorkingYears, TrainingTimesLastYear, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager\n",
            "Example scaling applied (to df_scaled_example, not df). First 5 Age/MonthlyIncome:\n",
            "| Age      | MonthlyIncome   |\n",
            "|:---------|:----------------|\n",
            "| 0.547619 | 0.262454        |\n",
            "| 0.738095 | 0.217009        |\n",
            "| 0.452381 | 0.0569247       |\n",
            "| 0.357143 | 0.100053        |\n",
            "| 0.214286 | 0.129489        |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 8: Save the Cleaned Dataset ---\n",
        "print(\"\\n--- Step 8: Save the Cleaned Dataset ---\")\n",
        "# The DataFrame 'df' now contains the cleaned data (after steps 1-6).\n",
        "# If you applied scaling permanently in Step 7, 'df' would reflect that too.\n",
        "cleaned_file_name = 'cleaned_WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
        "print(f\"Saving the cleaned data to '{cleaned_file_name}'...\")\n",
        "\n",
        "try:\n",
        "    # Save the final DataFrame to a CSV file\n",
        "    df.to_csv(cleaned_file_name, index=False)\n",
        "    print(f\"Cleaned dataset successfully saved.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the file: {e}\")\n",
        "\n",
        "print(\"\\n--- Data Cleaning Process Completed ---\")\n",
        "# Display final info of the cleaned dataframe 'df'\n",
        "print(\"\\nFinal Cleaned Dataset Info:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcwekUL-s8p1",
        "outputId": "8d28d0d4-a76a-41aa-9a5c-93ef7d8453ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 8: Save the Cleaned Dataset ---\n",
            "Saving the cleaned data to 'cleaned_WA_Fn-UseC_-HR-Employee-Attrition.csv'...\n",
            "Cleaned dataset successfully saved.\n",
            "\n",
            "--- Data Cleaning Process Completed ---\n",
            "\n",
            "Final Cleaned Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 46 columns):\n",
            " #   Column                             Non-Null Count  Dtype\n",
            "---  ------                             --------------  -----\n",
            " 0   Age                                1470 non-null   int64\n",
            " 1   Attrition                          1470 non-null   int64\n",
            " 2   DailyRate                          1470 non-null   int64\n",
            " 3   DistanceFromHome                   1470 non-null   int64\n",
            " 4   Education                          1470 non-null   int64\n",
            " 5   EmployeeNumber                     1470 non-null   int64\n",
            " 6   EnvironmentSatisfaction            1470 non-null   int64\n",
            " 7   HourlyRate                         1470 non-null   int64\n",
            " 8   JobInvolvement                     1470 non-null   int64\n",
            " 9   JobLevel                           1470 non-null   int64\n",
            " 10  JobSatisfaction                    1470 non-null   int64\n",
            " 11  MonthlyIncome                      1470 non-null   int64\n",
            " 12  MonthlyRate                        1470 non-null   int64\n",
            " 13  NumCompaniesWorked                 1470 non-null   int64\n",
            " 14  PercentSalaryHike                  1470 non-null   int64\n",
            " 15  PerformanceRating                  1470 non-null   int64\n",
            " 16  RelationshipSatisfaction           1470 non-null   int64\n",
            " 17  StockOptionLevel                   1470 non-null   int64\n",
            " 18  TotalWorkingYears                  1470 non-null   int64\n",
            " 19  TrainingTimesLastYear              1470 non-null   int64\n",
            " 20  WorkLifeBalance                    1470 non-null   int64\n",
            " 21  YearsAtCompany                     1470 non-null   int64\n",
            " 22  YearsInCurrentRole                 1470 non-null   int64\n",
            " 23  YearsSinceLastPromotion            1470 non-null   int64\n",
            " 24  YearsWithCurrManager               1470 non-null   int64\n",
            " 25  BusinessTravel_Travel_Frequently   1470 non-null   int64\n",
            " 26  BusinessTravel_Travel_Rarely       1470 non-null   int64\n",
            " 27  Department_Research & Development  1470 non-null   int64\n",
            " 28  Department_Sales                   1470 non-null   int64\n",
            " 29  EducationField_Life Sciences       1470 non-null   int64\n",
            " 30  EducationField_Marketing           1470 non-null   int64\n",
            " 31  EducationField_Medical             1470 non-null   int64\n",
            " 32  EducationField_Other               1470 non-null   int64\n",
            " 33  EducationField_Technical Degree    1470 non-null   int64\n",
            " 34  Gender_Male                        1470 non-null   int64\n",
            " 35  JobRole_Human Resources            1470 non-null   int64\n",
            " 36  JobRole_Laboratory Technician      1470 non-null   int64\n",
            " 37  JobRole_Manager                    1470 non-null   int64\n",
            " 38  JobRole_Manufacturing Director     1470 non-null   int64\n",
            " 39  JobRole_Research Director          1470 non-null   int64\n",
            " 40  JobRole_Research Scientist         1470 non-null   int64\n",
            " 41  JobRole_Sales Executive            1470 non-null   int64\n",
            " 42  JobRole_Sales Representative       1470 non-null   int64\n",
            " 43  MaritalStatus_Married              1470 non-null   int64\n",
            " 44  MaritalStatus_Single               1470 non-null   int64\n",
            " 45  OverTime_Yes                       1470 non-null   int64\n",
            "dtypes: int64(46)\n",
            "memory usage: 528.4 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Check new cleanned data\n",
        "# Define the path to the cleaned file\n",
        "cleaned_file_path = 'cleaned_WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
        "\n",
        "print(f\"--- Verifying the cleaned dataset: '{cleaned_file_path}' ---\")\n",
        "\n",
        "try:\n",
        "    # Load the cleaned dataset\n",
        "    df_cleaned = pd.read_csv(cleaned_file_path)\n",
        "    print(f\"\\nDataset '{cleaned_file_path}' loaded successfully.\")\n",
        "\n",
        "    # 1. Re-check for Missing Values\n",
        "    print(\"\\n--- 1. Checking for Missing Values ---\")\n",
        "    missing_values_cleaned = df_cleaned.isnull().sum()\n",
        "    missing_values_cleaned = missing_values_cleaned[missing_values_cleaned > 0]\n",
        "    if missing_values_cleaned.empty:\n",
        "        print(\"Verification PASSED: No missing values found.\")\n",
        "    else:\n",
        "        print(\"Verification FAILED: Missing values found in the cleaned file:\")\n",
        "        print(missing_values_cleaned.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "    # 2. Re-check for Duplicate Rows\n",
        "    print(\"\\n--- 2. Checking for Duplicate Rows ---\")\n",
        "    num_duplicates_cleaned = df_cleaned.duplicated().sum()\n",
        "    if num_duplicates_cleaned == 0:\n",
        "        print(\"Verification PASSED: No duplicate rows found.\")\n",
        "    else:\n",
        "        print(f\"Verification FAILED: Found {num_duplicates_cleaned} duplicate rows in the cleaned file.\")\n",
        "\n",
        "    # 3. Check if Single-Value Columns were Removed\n",
        "    print(\"\\n--- 3. Checking for Absence of Single-Value Columns ---\")\n",
        "    original_single_value_cols = ['EmployeeCount', 'Over18', 'StandardHours']\n",
        "    cols_still_present = [col for col in original_single_value_cols if col in df_cleaned.columns]\n",
        "    if not cols_still_present:\n",
        "        print(\"Verification PASSED: Single-value columns ('EmployeeCount', 'Over18', 'StandardHours') are absent.\")\n",
        "    else:\n",
        "        print(f\"Verification FAILED: The following single-value columns are still present: {', '.join(cols_still_present)}\")\n",
        "\n",
        "    # 4. Check Data Types for Encoding\n",
        "    print(\"\\n--- 4. Checking Data Types for Encoding ---\")\n",
        "    object_columns = df_cleaned.select_dtypes(include='object').columns.tolist()\n",
        "    # EmployeeNumber is expected to remain as int64, not object. Attrition should be int64 after mapping.\n",
        "    # All other original object columns should now be numerical (int/uint8 from get_dummies).\n",
        "    unexpected_object_cols = [col for col in object_columns if col != 'EmployeeNumber'] # Adjust if EmployeeNumber is expected as object\n",
        "\n",
        "    if not unexpected_object_cols:\n",
        "        print(\"Verification PASSED: No unexpected 'object' type columns found (indicating successful encoding).\")\n",
        "        # Optionally check if Attrition is now numeric\n",
        "        if 'Attrition' in df_cleaned.columns and pd.api.types.is_numeric_dtype(df_cleaned['Attrition']):\n",
        "             print(\"  - 'Attrition' column is correctly mapped to a numeric type.\")\n",
        "        elif 'Attrition' in df_cleaned.columns:\n",
        "             print(f\"  - Warning: 'Attrition' column is present but has type {df_cleaned['Attrition'].dtype}, expected numeric.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Verification FAILED: Found unexpected 'object' type columns: {', '.join(unexpected_object_cols)}\")\n",
        "\n",
        "    # 5. Check Final Shape and Columns (Optional)\n",
        "    print(\"\\n--- 5. Final Shape and Columns Overview ---\")\n",
        "    print(f\"Shape of the cleaned dataset: {df_cleaned.shape}\")\n",
        "    print(\"Columns in the cleaned dataset:\")\n",
        "    print(df_cleaned.columns.tolist())\n",
        "    print(\"\\nCleaned Dataset Info:\")\n",
        "    df_cleaned.info()\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The cleaned file '{cleaned_file_path}' was not found. Please ensure Step 8 ran successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during verification: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MayJHKsVufcj",
        "outputId": "875e9bf7-bf60-4ce8-e97c-fc4043d772af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Verifying the cleaned dataset: 'cleaned_WA_Fn-UseC_-HR-Employee-Attrition.csv' ---\n",
            "\n",
            "Dataset 'cleaned_WA_Fn-UseC_-HR-Employee-Attrition.csv' loaded successfully.\n",
            "\n",
            "--- 1. Checking for Missing Values ---\n",
            "Verification PASSED: No missing values found.\n",
            "\n",
            "--- 2. Checking for Duplicate Rows ---\n",
            "Verification PASSED: No duplicate rows found.\n",
            "\n",
            "--- 3. Checking for Absence of Single-Value Columns ---\n",
            "Verification PASSED: Single-value columns ('EmployeeCount', 'Over18', 'StandardHours') are absent.\n",
            "\n",
            "--- 4. Checking Data Types for Encoding ---\n",
            "Verification PASSED: No unexpected 'object' type columns found (indicating successful encoding).\n",
            "  - 'Attrition' column is correctly mapped to a numeric type.\n",
            "\n",
            "--- 5. Final Shape and Columns Overview ---\n",
            "Shape of the cleaned dataset: (1470, 46)\n",
            "Columns in the cleaned dataset:\n",
            "['Age', 'Attrition', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeNumber', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'BusinessTravel_Travel_Frequently', 'BusinessTravel_Travel_Rarely', 'Department_Research & Development', 'Department_Sales', 'EducationField_Life Sciences', 'EducationField_Marketing', 'EducationField_Medical', 'EducationField_Other', 'EducationField_Technical Degree', 'Gender_Male', 'JobRole_Human Resources', 'JobRole_Laboratory Technician', 'JobRole_Manager', 'JobRole_Manufacturing Director', 'JobRole_Research Director', 'JobRole_Research Scientist', 'JobRole_Sales Executive', 'JobRole_Sales Representative', 'MaritalStatus_Married', 'MaritalStatus_Single', 'OverTime_Yes']\n",
            "\n",
            "Cleaned Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 46 columns):\n",
            " #   Column                             Non-Null Count  Dtype\n",
            "---  ------                             --------------  -----\n",
            " 0   Age                                1470 non-null   int64\n",
            " 1   Attrition                          1470 non-null   int64\n",
            " 2   DailyRate                          1470 non-null   int64\n",
            " 3   DistanceFromHome                   1470 non-null   int64\n",
            " 4   Education                          1470 non-null   int64\n",
            " 5   EmployeeNumber                     1470 non-null   int64\n",
            " 6   EnvironmentSatisfaction            1470 non-null   int64\n",
            " 7   HourlyRate                         1470 non-null   int64\n",
            " 8   JobInvolvement                     1470 non-null   int64\n",
            " 9   JobLevel                           1470 non-null   int64\n",
            " 10  JobSatisfaction                    1470 non-null   int64\n",
            " 11  MonthlyIncome                      1470 non-null   int64\n",
            " 12  MonthlyRate                        1470 non-null   int64\n",
            " 13  NumCompaniesWorked                 1470 non-null   int64\n",
            " 14  PercentSalaryHike                  1470 non-null   int64\n",
            " 15  PerformanceRating                  1470 non-null   int64\n",
            " 16  RelationshipSatisfaction           1470 non-null   int64\n",
            " 17  StockOptionLevel                   1470 non-null   int64\n",
            " 18  TotalWorkingYears                  1470 non-null   int64\n",
            " 19  TrainingTimesLastYear              1470 non-null   int64\n",
            " 20  WorkLifeBalance                    1470 non-null   int64\n",
            " 21  YearsAtCompany                     1470 non-null   int64\n",
            " 22  YearsInCurrentRole                 1470 non-null   int64\n",
            " 23  YearsSinceLastPromotion            1470 non-null   int64\n",
            " 24  YearsWithCurrManager               1470 non-null   int64\n",
            " 25  BusinessTravel_Travel_Frequently   1470 non-null   int64\n",
            " 26  BusinessTravel_Travel_Rarely       1470 non-null   int64\n",
            " 27  Department_Research & Development  1470 non-null   int64\n",
            " 28  Department_Sales                   1470 non-null   int64\n",
            " 29  EducationField_Life Sciences       1470 non-null   int64\n",
            " 30  EducationField_Marketing           1470 non-null   int64\n",
            " 31  EducationField_Medical             1470 non-null   int64\n",
            " 32  EducationField_Other               1470 non-null   int64\n",
            " 33  EducationField_Technical Degree    1470 non-null   int64\n",
            " 34  Gender_Male                        1470 non-null   int64\n",
            " 35  JobRole_Human Resources            1470 non-null   int64\n",
            " 36  JobRole_Laboratory Technician      1470 non-null   int64\n",
            " 37  JobRole_Manager                    1470 non-null   int64\n",
            " 38  JobRole_Manufacturing Director     1470 non-null   int64\n",
            " 39  JobRole_Research Director          1470 non-null   int64\n",
            " 40  JobRole_Research Scientist         1470 non-null   int64\n",
            " 41  JobRole_Sales Executive            1470 non-null   int64\n",
            " 42  JobRole_Sales Representative       1470 non-null   int64\n",
            " 43  MaritalStatus_Married              1470 non-null   int64\n",
            " 44  MaritalStatus_Single               1470 non-null   int64\n",
            " 45  OverTime_Yes                       1470 non-null   int64\n",
            "dtypes: int64(46)\n",
            "memory usage: 528.4 KB\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}